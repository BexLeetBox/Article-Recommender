{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_impressions = pd.read_csv(\n",
    "    \"../MIND/train/behaviors.tsv\",\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=[\"impressionId\", \"userId\", \"time\", \"history\", \"impressions\"],\n",
    "    usecols=[\"userId\", \"impressions\"]\n",
    "  )\n",
    "\n",
    "raw_news = pd.read_csv(\n",
    "  \"../MIND/train/news.tsv\",\n",
    "  sep=\"\\t\", \n",
    "  header=None,\n",
    "  names=[\"newsId\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"titleEntities\", \"abstractEntities\"],\n",
    "  usecols=[\"newsId\", \"title\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   userId  100000 non-null  int64\n",
      " 1   newsId  100000 non-null  int64\n",
      " 2   click   100000 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.3 MB\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "impressions = raw_impressions\n",
    "\n",
    "def str2int(x):\n",
    "  m = re.search(r\"\\d+\", x)\n",
    "  if not m:\n",
    "    raise Exception(\"didn't find news id\")\n",
    "  return int(m.group())\n",
    "\n",
    "def str2click(x):\n",
    "  m = re.search(r\"-(\\d)\", x)\n",
    "  if not m: \n",
    "    raise Exception(\"didnt find click info\")\n",
    "  return int(m.group(1))\n",
    "\n",
    "impressions = impressions.dropna()\n",
    "\n",
    "impressions[\"click\"] = impressions[\"impressions\"].apply(lambda x: x.split(\" \"))\n",
    "impressions = impressions.explode(\"click\").reset_index()\n",
    "impressions = impressions.head(100_000)\n",
    "\n",
    "impressions[\"newsId\"] = impressions[\"click\"].apply(str2int)\n",
    "impressions[\"userId\"] = impressions[\"userId\"].apply(str2int)\n",
    "impressions[\"click\"] = impressions[\"click\"].apply(str2click)\n",
    "\n",
    "impressions = impressions[[\"userId\", \"newsId\", \"click\"]]\n",
    "impressions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Make user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = impressions[\"userId\"].unique()\n",
    "news_ids = impressions[\"newsId\"].unique()\n",
    "\n",
    "M = len(user_ids)\n",
    "N = len(news_ids)\n",
    "\n",
    "uid2index = {id: i for i, id in enumerate(user_ids)}\n",
    "nid2index = {id: i for i, id in enumerate(news_ids)}\n",
    "\n",
    "def make_X(df: DataFrame):\n",
    "    \n",
    "\n",
    "  rows = [uid2index[uid] for uid in df[\"userId\"]]\n",
    "  cols = [nid2index[nid] for nid in df[\"newsId\"]]\n",
    "\n",
    "  data = df[\"click\"]\n",
    "\n",
    "  X = csr_matrix((data, (rows, cols)), shape=(M, N))\n",
    "\n",
    "  return X\n",
    "\n",
    "X = make_X(impressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Item-based CF\n",
    "item_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "item_knn.fit(X.T)\n",
    "\n",
    "# User-based CF\n",
    "user_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "user_knn.fit(X)\n",
    "\n",
    "def recommend_items_item_based(user_index, X, item_knn, n_recommendations=5):\n",
    "    # Find items this user has interacted with\n",
    "    user_items = X[user_index].nonzero()[1]\n",
    "    \n",
    "    # Initialize recommendation scores\n",
    "    recommendations = np.zeros(X.shape[1])\n",
    "    \n",
    "    for item in user_items:\n",
    "        # Find similar items\n",
    "        distances, indices = item_knn.kneighbors(\n",
    "            X.T[item].reshape(1, -1), \n",
    "            n_neighbors=11  # Including itself\n",
    "        )\n",
    "        \n",
    "        # Convert distances to similarities and remove the item itself\n",
    "        similarities = 1 - distances.flatten()\n",
    "        similar_items = indices.flatten()\n",
    "        \n",
    "        # Skip the first one as it's the item itself\n",
    "        for i, similar_item in enumerate(similar_items[1:]):\n",
    "            # Weight by similarity\n",
    "            recommendations[similar_item] += similarities[i+1]\n",
    "    \n",
    "    # Filter out items the user has already interacted with\n",
    "    recommendations[user_items] = 0\n",
    "    \n",
    "    # Get top recommendations\n",
    "    top_recommendations = recommendations.argsort()[-n_recommendations:][::-1]\n",
    "    \n",
    "    return top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Number of latent factors\n",
    "n_factors = 50\n",
    "\n",
    "# Initialize NMF model\n",
    "nmf_model = NMF(n_components=n_factors, init='random', random_state=42)\n",
    "\n",
    "# Fit the model to the user-item matrix\n",
    "user_factors = nmf_model.fit_transform(X)\n",
    "item_factors = nmf_model.components_\n",
    "\n",
    "# Generate recommendations for a user\n",
    "def recommend_items_mf(user_index, user_factors, item_factors, X, n_recommendations=5):\n",
    "    # Predict ratings for all items\n",
    "    user_vector = user_factors[user_index].reshape(1, -1)\n",
    "    predicted_ratings = np.dot(user_vector, item_factors)\n",
    "    \n",
    "    # Set already interacted items to zero\n",
    "    user_items = X[user_index].nonzero()[1]\n",
    "    predicted_ratings[0, user_items] = 0\n",
    "    \n",
    "    # Get top recommendations\n",
    "    top_recommendations = predicted_ratings[0].argsort()[-n_recommendations:][::-1]\n",
    "    \n",
    "    return top_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NMF model once...\n",
      "Model fitting time: 6.70 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating users: 100%|██████████| 2237/2237 [00:04<00:00, 459.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision@5: 0.0254\n",
      "Mean Recall@5: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_recommender_optimized(interactions_df, method='mf', test_size=0.2, k=5):\n",
    "    train_df, test_df = train_test_split(interactions_df, test_size=test_size, random_state=42)\n",
    "    \n",
    "    train_matrix = make_X(train_df)\n",
    "    \n",
    "    test_users = np.array([uid2index[uid] for uid in test_df['userId']])\n",
    "    test_items = np.array([nid2index[nid] for nid in test_df['newsId']])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    if method == 'mf':\n",
    "        print(\"Fitting NMF model once...\")\n",
    "        nmf_model = NMF(n_components=50, init='random', random_state=42)\n",
    "        user_factors = nmf_model.fit_transform(train_matrix)\n",
    "        item_factors = nmf_model.components_\n",
    "    else:\n",
    "        print(\"Fitting item KNN model once...\")\n",
    "        item_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "        item_knn.fit(train_matrix.T)\n",
    "    \n",
    "    print(f\"Model fitting time: {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    precision_at_k = []\n",
    "    recall_at_k = []\n",
    "\n",
    "    unique_test_users = np.unique(test_users)\n",
    "    \n",
    "    for user_idx in tqdm(unique_test_users, desc=\"Evaluating users\"):\n",
    "        if method == 'mf':\n",
    "            recommendations = recommend_items_mf(user_idx, user_factors, item_factors, train_matrix, n_recommendations=k)\n",
    "        else:\n",
    "            recommendations = recommend_items_item_based(user_idx, train_matrix, item_knn, n_recommendations=k)\n",
    "        \n",
    "        actual_items = test_items[test_users == user_idx]\n",
    "        \n",
    "        common_items = len(set(recommendations).intersection(set(actual_items)))\n",
    "        precision = common_items / len(recommendations) if recommendations.size > 0 else 0\n",
    "        recall = common_items / len(actual_items) if len(actual_items) > 0 else 0\n",
    "        \n",
    "        precision_at_k.append(precision)\n",
    "        recall_at_k.append(recall)\n",
    "    \n",
    "    mean_precision = np.mean(precision_at_k)\n",
    "    mean_recall = np.mean(recall_at_k)\n",
    "    \n",
    "    print(f\"Mean Precision@{k}: {mean_precision:.4f}\")\n",
    "    print(f\"Mean Recall@{k}: {mean_recall:.4f}\")\n",
    "    \n",
    "    return mean_precision, mean_recall\n",
    "\n",
    "\n",
    "\n",
    "precision, recall = evaluate_recommender_optimized(impressions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
