{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T10:57:41.918404Z",
     "start_time": "2025-03-11T10:57:40.431329200Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News DataFrame Head:\n",
      "  news_id   category      subcategory  \\\n",
      "0  N55528  lifestyle  lifestyleroyals   \n",
      "1  N19639     health       weightloss   \n",
      "2  N61837       news        newsworld   \n",
      "3  N53526     health           voices   \n",
      "4  N38324     health          medical   \n",
      "\n",
      "                                               title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1                      50 Worst Habits For Belly Fat   \n",
      "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "3  I Was An NBA Wife. Here's How It Affected My M...   \n",
      "4  How to Get Rid of Skin Tags, According to a De...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  These seemingly harmless habits are holding yo...   \n",
      "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "3  I felt like I was a fraud, and being an NBA wi...   \n",
      "4  They seem harmless, but there's a very good re...   \n",
      "\n",
      "                                             url  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "3  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
      "4  https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
      "\n",
      "                                      title_entities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
      "\n",
      "                                   abstract_entities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
      "3  [{\"Label\": \"National Basketball Association\", ...  \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
      "\n",
      "Behaviors DataFrame Head:\n",
      "   impression_id user_id                   time  \\\n",
      "0              1  U13740  11/11/2019 9:05:58 AM   \n",
      "1              2  U91836  11/12/2019 6:11:30 PM   \n",
      "2              3  U73700  11/14/2019 7:01:48 AM   \n",
      "3              4  U34670  11/11/2019 5:28:05 AM   \n",
      "4              5   U8125  11/12/2019 4:11:21 PM   \n",
      "\n",
      "                                             history  \\\n",
      "0  N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
      "1  N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
      "2  N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
      "3  N45729 N2203 N871 N53880 N41375 N43142 N33013 ...   \n",
      "4                        N10078 N56514 N14904 N33740   \n",
      "\n",
      "                                         impressions  \n",
      "0                                  N55689-1 N35729-0  \n",
      "1  N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...  \n",
      "2  N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...  \n",
      "3                N35729-0 N33632-0 N49685-1 N27581-0  \n",
      "4  N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths (adjust if your file paths differ)\n",
    "news_file = '../MINDsmall_train/news.tsv'\n",
    "behaviors_train_file = '../MINDsmall_train/behaviors.tsv'\n",
    "behaviors_dev_file = '../MINDsmall_dev/behaviors.tsv'\n",
    "# Define column names for each file\n",
    "news_cols = ['news_id', 'category', 'subcategory', 'title',\n",
    "             'abstract', 'url', 'title_entities', 'abstract_entities']\n",
    "behaviors_train_cols = ['impression_id', 'user_id', 'time', 'history', 'impressions']\n",
    "behaviors_dev_cols = ['impression_id', 'user_id', 'time', 'history', 'impressions']\n",
    "# Load news data and print head\n",
    "news_df = pd.read_csv(news_file, sep='\\t', header=None, names=news_cols)\n",
    "print(\"News DataFrame Head:\")\n",
    "print(news_df.head(), \"\\n\")\n",
    "\n",
    "# Load behaviors data and print head\n",
    "behaviors_train_df = pd.read_csv(behaviors_train_file, sep='\\t', header=None, names=behaviors_train_cols)\n",
    "behaviors_dev_df = pd.read_csv(behaviors_dev_file, sep='\\t', header=None, names=behaviors_dev_cols)\n",
    "print(\"Behaviors DataFrame Head:\")\n",
    "print(behaviors_train_df.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d65d5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users in training set: 50000\n",
      "Number of unique users in development set: 50000\n"
     ]
    }
   ],
   "source": [
    "# Count unique users in train and dev sets\n",
    "unique_train_users = behaviors_train_df['user_id'].nunique()\n",
    "unique_dev_users = behaviors_dev_df['user_id'].nunique()\n",
    "\n",
    "print(f\"Number of unique users in training set: {unique_train_users}\")\n",
    "print(f\"Number of unique users in development set: {unique_dev_users}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14942dc81740a6d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T10:57:42.314113600Z",
     "start_time": "2025-03-11T10:57:41.918404Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0:\n",
      "  Entity: Q41\n",
      "  Vector (length=100): [-0.063388 -0.181451  0.057501 -0.091254 -0.076217 -0.052525  0.0505\n",
      " -0.224871 -0.018145  0.030722  0.064276  0.073063  0.039489  0.159404\n",
      " -0.128784  0.016325  0.026797  0.13709   0.001849 -0.059103  0.012091\n",
      "  0.045418  0.000591  0.211337 -0.034093 -0.074582  0.014004 -0.099355\n",
      "  0.170144  0.109376 -0.014797  0.071172  0.080375  0.045563 -0.046462\n",
      "  0.070108  0.015413 -0.020874 -0.170324 -0.00113   0.05981   0.054342\n",
      "  0.027358 -0.028995 -0.224508  0.066281 -0.200006  0.018186  0.082396\n",
      "  0.167178 -0.136239  0.055134 -0.080195 -0.00146   0.031078 -0.017084\n",
      " -0.091176 -0.036916  0.124642 -0.098185 -0.054836  0.152483 -0.053712\n",
      "  0.092816 -0.112044 -0.072247 -0.114896 -0.036541 -0.186339 -0.16061\n",
      "  0.037342 -0.133474  0.11008   0.070678 -0.005586 -0.046667 -0.07201\n",
      "  0.086424  0.026165  0.030561  0.077888 -0.117226  0.211597  0.112512\n",
      "  0.079999 -0.083398 -0.121117  0.071751 -0.017654 -0.134979 -0.051949\n",
      "  0.001861  0.124535 -0.151043 -0.263698 -0.103607  0.020007 -0.101157\n",
      " -0.091567  0.035234]\n",
      "\n",
      "Line 1:\n",
      "  Entity: Q1860\n",
      "  Vector (length=100): [ 0.060958  0.069934  0.015832  0.079471 -0.023362 -0.125007 -0.043618\n",
      "  0.134063 -0.121691  0.089166  0.129177  0.148145  0.027196 -0.060636\n",
      "  0.06876   0.071959  0.150306 -0.099519 -0.050912  0.123948 -0.190319\n",
      " -0.096762 -0.006279 -0.08681  -0.026199  0.017013  0.043436  0.058991\n",
      " -0.131758  0.032473 -0.137706 -0.009527  0.085008 -0.060163  0.044856\n",
      "  0.03002  -0.042486 -0.098337 -0.024715  0.054446 -0.05623   0.161813\n",
      " -0.106716 -0.052167  0.013636  0.132148  0.044919  0.074031 -0.085483\n",
      " -0.083199 -0.007451  0.113236  0.098931 -0.079819 -0.02629   0.051472\n",
      " -0.092252  0.068104  0.016942  0.009106 -0.062264 -0.001102  0.050228\n",
      "  0.016879 -0.026729 -0.051632 -0.08304  -0.14388   0.066569 -0.014793\n",
      " -0.047219 -0.03439   0.009343 -0.002716 -0.094623  0.000528 -0.055017\n",
      " -0.013458 -0.038277 -0.067144  0.091749  0.018254 -0.080948  0.06285\n",
      "  0.117076 -0.115282  0.050163  0.091078 -0.166571  0.056171 -0.070713\n",
      " -0.014287  0.013578  0.099977  0.012199 -0.141138  0.056129 -0.133727\n",
      "  0.025795  0.051448]\n",
      "\n",
      "Line 2:\n",
      "  Entity: Q39631\n",
      "  Vector (length=100): [-9.31060e-02 -5.20020e-02  2.05560e-02 -2.08010e-02  4.31800e-02\n",
      " -7.23210e-02  9.10000e-04  2.81560e-02  1.76303e-01  3.53960e-02\n",
      "  7.26420e-02  2.39000e-04 -1.71645e-01 -3.48160e-02 -1.06319e-01\n",
      " -8.21870e-02 -2.23220e-02 -1.21248e-01 -8.49620e-02 -1.46949e-01\n",
      " -1.53640e-02  2.40605e-01 -1.65207e-01  3.39260e-02 -5.55610e-02\n",
      "  2.63102e-01 -1.82810e-02 -7.16300e-02  6.73490e-02  2.19430e-02\n",
      " -6.66420e-02  1.54693e-01  3.95140e-02 -1.15533e-01  1.57337e-01\n",
      " -1.81090e-02  9.35550e-02 -1.36766e-01 -1.06228e-01  2.08970e-02\n",
      "  3.00240e-02 -1.09274e-01 -1.20507e-01  4.67960e-02  1.60820e-02\n",
      "  6.35810e-02  2.14720e-02 -1.77214e-01 -3.77780e-02  8.98670e-02\n",
      "  1.40730e-02  1.48010e-02 -8.38970e-02 -9.86800e-03  6.58590e-02\n",
      " -1.92299e-01  1.38850e-02  3.57290e-02  2.55410e-02 -1.07844e-01\n",
      " -2.15149e-01  9.02720e-02  1.31670e-01 -6.58070e-02 -1.19546e-01\n",
      "  1.31104e-01 -8.73230e-02  1.18188e-01  1.66771e-01  1.43170e-02\n",
      "  1.17788e-01 -6.90880e-02  2.96300e-03 -8.58800e-03  1.60640e-02\n",
      "  7.93400e-03 -1.15904e-01 -6.65420e-02  7.19870e-02  7.86460e-02\n",
      " -3.68280e-02 -1.34134e-01 -1.58453e-01  7.77070e-02 -2.85140e-02\n",
      " -1.55193e-01 -4.70590e-02  3.56940e-02 -1.07131e-01 -3.72000e-04\n",
      " -1.24472e-01 -8.68400e-02 -7.89920e-02 -6.27120e-02  5.11170e-02\n",
      " -1.84307e-01  1.27637e-01 -1.44866e-01  4.46900e-02  1.34980e-02]\n",
      "\n",
      "Line 3:\n",
      "  Entity: Q30\n",
      "  Vector (length=100): [-1.15737e-01 -1.79113e-01  1.02739e-01 -1.12469e-01 -1.01853e-01\n",
      " -1.77516e-01  1.58600e-02 -9.26260e-02  8.67080e-02  5.78500e-02\n",
      "  1.76422e-01  7.06680e-02  7.15840e-02  3.05330e-02 -1.79654e-01\n",
      " -3.23120e-02  4.75960e-02 -2.87510e-02 -3.12930e-02 -4.42830e-02\n",
      " -1.44224e-01 -8.95420e-02 -4.60000e-02  2.15515e-01  7.52960e-02\n",
      " -6.23320e-02 -2.45600e-03  3.52930e-02  1.09550e-01  5.28090e-02\n",
      " -8.17340e-02  6.61010e-02  1.48733e-01 -7.30030e-02  7.50380e-02\n",
      " -9.92130e-02 -9.17320e-02 -1.14809e-01 -6.31780e-02  7.69270e-02\n",
      " -6.62330e-02  1.30834e-01 -8.19430e-02 -1.78940e-02 -8.41290e-02\n",
      " -9.83960e-02 -7.64250e-02  1.45224e-01  4.76620e-02  6.11240e-02\n",
      " -1.47525e-01 -3.52320e-02  8.01320e-02  7.53150e-02  6.62640e-02\n",
      "  5.32240e-02 -8.28200e-03  3.85510e-02 -4.45590e-02 -8.11080e-02\n",
      " -7.82840e-02  1.16180e-01  8.25310e-02  1.01352e-01  5.42690e-02\n",
      " -1.93552e-01 -1.44609e-01 -1.09713e-01 -2.60490e-02 -2.00090e-02\n",
      " -1.21075e-01 -2.18548e-01  1.50953e-01  7.20830e-02 -8.96450e-02\n",
      " -4.47100e-03 -4.93310e-02  1.89673e-01  1.63100e-03  1.56474e-01\n",
      " -2.24640e-02 -8.21980e-02  6.98810e-02  1.83586e-01  1.75343e-01\n",
      "  5.14600e-03 -2.83980e-02  2.69720e-02 -1.05001e-01 -1.91770e-02\n",
      "  5.89300e-03  8.05110e-02 -8.50000e-05 -8.99680e-02 -8.34860e-02\n",
      " -1.49992e-01 -5.30310e-02 -1.36071e-01 -2.90010e-02  1.74155e-01]\n",
      "\n",
      "Line 4:\n",
      "  Entity: Q60\n",
      "  Vector (length=100): [-0.051036 -0.165637  0.132802 -0.089949 -0.146637 -0.142246  0.103853\n",
      " -0.129651  0.096265  0.017288  0.096343  0.120867  0.139412 -0.101083\n",
      " -0.105518 -0.044083 -0.081574  0.00825  -0.064942 -0.139662 -0.079039\n",
      "  0.029418 -0.049928  0.183146 -0.028249 -0.062579 -0.009422 -0.038783\n",
      "  0.099171  0.117744 -0.073817  0.030925  0.072817 -0.074308 -0.058244\n",
      "  0.053969 -0.176053 -0.110216 -0.087142 -0.031469 -0.138299  0.008009\n",
      " -0.02006  -0.068153 -0.157539 -0.10143  -0.050036  0.041379 -0.044153\n",
      "  0.013049 -0.299345  0.061024  0.156111  0.050081  0.044341 -0.033624\n",
      "  0.023531 -0.030379  0.027055 -0.134954 -0.084445  0.103199  0.057259\n",
      "  0.082226  0.028525 -0.180036 -0.129249 -0.131783 -0.041311 -0.038343\n",
      " -0.133523 -0.177585  0.153199  0.074922 -0.123952 -0.087973  0.018191\n",
      "  0.186848  0.074991  0.036592  0.086934  0.031789  0.094553  0.132498\n",
      "  0.139359  0.012824 -0.008956 -0.02369  -0.09444  -0.11028  -0.002713\n",
      "  0.078628  0.003711 -0.058953 -0.154067 -0.117159 -0.031614 -0.140451\n",
      "  0.001288  0.14035 ]\n",
      "Total embeddings loaded: 26904\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_file = '../MINDsmall_train/entity_embedding.vec'\n",
    "\n",
    "# Load entity embeddings\n",
    "def load_embeddings(embedding_file):\n",
    "    embeddings = {}\n",
    "    with open(embedding_file, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # Split on whitespace\n",
    "            parts = line.strip().split()\n",
    "            \n",
    "            # The first token is the entity ID, the rest are the vector values\n",
    "            entity = parts[0]\n",
    "            vector = np.array([float(x) for x in parts[1:]], dtype=np.float32)\n",
    "            embeddings[entity] = vector\n",
    "            \n",
    "            # For debugging, just print the first few lines, then stop\n",
    "            if i < 5:  # print the first 5 lines\n",
    "                print(f\"Line {i}:\")\n",
    "                print(f\"  Entity: {entity}\")\n",
    "                print(f\"  Vector (length={len(vector)}): {vector}\\n\")\n",
    "    \n",
    "    # Print total embeddings loaded\n",
    "    print(f\"Total embeddings loaded: {len(embeddings)}\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Actually load and print a sample\n",
    "embeddings = load_embeddings(embedding_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da6e83eec9fa6c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T10:57:42.665037600Z",
     "start_time": "2025-03-11T10:57:42.311359400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed entity IDs (head):\n",
      "                                      title_entities         title_entity_ids\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...  [Q80976, Q43274, Q9682]\n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...                [Q193583]\n",
      "2                                                 []                       []\n",
      "3                                                 []                       []\n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...               [Q3179593]\n",
      "0    [Q80976, Q43274, Q9682]\n",
      "1                  [Q193583]\n",
      "2                         []\n",
      "3                         []\n",
      "4                 [Q3179593]\n",
      "Name: title_entity_ids, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def parse_entity_list(entity_col):\n",
    "    \"\"\"\n",
    "    Parses the JSON in the entity columns to extract a list of Wikidata IDs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(entity_col)  # convert string to Python list/dict\n",
    "        # Extract 'WikidataId' from each object if present\n",
    "        wikidata_ids = [obj['WikidataId'] for obj in data if 'WikidataId' in obj]\n",
    "        return wikidata_ids\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        # Return empty list if parsing fails\n",
    "        return []\n",
    "\n",
    "# Create a new column with parsed Wikidata IDs\n",
    "news_df['title_entity_ids'] = news_df['title_entities'].apply(parse_entity_list)\n",
    "\n",
    "# Optional: do the same for abstract_entities\n",
    "news_df['abstract_entity_ids'] = news_df['abstract_entities'].apply(parse_entity_list)\n",
    "\n",
    "# Quick check\n",
    "print(\"Parsed entity IDs (head):\")\n",
    "print(news_df[['title_entities', 'title_entity_ids']].head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(news_df['title_entity_ids'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d6a2e21d09a62a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T10:57:43.634829100Z",
     "start_time": "2025-03-11T10:57:42.665037600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles in news_df: 51282\n",
      "Total articles with embeddings: 37131\n",
      "Sample article IDs with vectors: [0, 1, 4, 5, 6]\n",
      "Sample vector shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "article_vectors = {}\n",
    "\n",
    "for idx, row in news_df.iterrows():\n",
    "    # idx is the news_id from set_index('news_id'), row is the row data\n",
    "    entity_ids = row['title_entity_ids']  # or combine with abstract_entity_ids if you want\n",
    "    \n",
    "    # Collect all entity embeddings that exist\n",
    "    valid_embeddings = []\n",
    "    for eid in entity_ids:\n",
    "        if eid in embeddings:\n",
    "            valid_embeddings.append(embeddings[eid])\n",
    "    \n",
    "    # If we found at least one valid embedding, average them\n",
    "    if valid_embeddings:\n",
    "        article_vectors[idx] = np.mean(valid_embeddings, axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "print(f\"Total articles in news_df: {len(news_df)}\")\n",
    "print(f\"Total articles with embeddings: {len(article_vectors)}\")\n",
    "\n",
    "# Show a few example keys\n",
    "some_keys = list(article_vectors.keys())[:5]\n",
    "print(\"Sample article IDs with vectors:\", some_keys)\n",
    "\n",
    "if some_keys:\n",
    "    print(\"Sample vector shape:\", article_vectors[some_keys[0]].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bc9e98b978712fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T10:57:46.972183900Z",
     "start_time": "2025-03-11T10:57:43.633649900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix shape: (37131, 37131)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "article_ids = list(article_vectors.keys())\n",
    "\n",
    "vectors = np.stack(list(article_vectors.values()), axis=0)\n",
    "\n",
    "similarity_matrix = cosine_similarity(vectors)  # shape: (37131, 37131)\n",
    "print(\"Similarity matrix shape:\", similarity_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae55b10f54fb5017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T10:57:46.984182900Z",
     "start_time": "2025-03-11T10:57:46.973184600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar articles to 0: [44779, 35826, 35391, 23508, 31447]\n"
     ]
    }
   ],
   "source": [
    "def get_similar_articles(article_id, article_ids, vectors, similarity_matrix, top_k=5):\n",
    "    try:\n",
    "        idx = article_ids.index(article_id)\n",
    "    except ValueError:\n",
    "        return []\n",
    "    \n",
    "    sim_scores = similarity_matrix[idx]  # all similarities for that article\n",
    "    ranked_indices = np.argsort(sim_scores)[::-1]  # descending\n",
    "    # skip itself, then take top_k\n",
    "    similar_ids = [article_ids[i] for i in ranked_indices if article_ids[i] != article_id]\n",
    "    return similar_ids[:top_k]\n",
    "\n",
    "# Example usage:\n",
    "example_article = article_ids[0]\n",
    "top_similar = get_similar_articles(example_article, article_ids, vectors, similarity_matrix, top_k=5)\n",
    "print(f\"Top similar articles to {example_article}:\", top_similar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "717c53623adf44cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T10:57:46.987689600Z",
     "start_time": "2025-03-11T10:57:46.984182900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user U123: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_for_user(user_id, clicked_articles, article_ids, article_vectors, top_k=5):\n",
    "    # Filter only those that have embeddings\n",
    "    valid_clicked = [aid for aid in clicked_articles if aid in article_vectors]\n",
    "    if not valid_clicked:\n",
    "        return []\n",
    "\n",
    "    # Average the userâ€™s clicked article vectors\n",
    "    user_profile = np.mean([article_vectors[aid] for aid in valid_clicked], axis=0).reshape(1, -1)\n",
    "\n",
    "    # Compute similarity to all articles\n",
    "    all_vectors = np.stack(article_vectors.values(), axis=0)\n",
    "    sim_scores = cosine_similarity(user_profile, all_vectors)[0]  # shape: (N,)\n",
    "    \n",
    "    # Sort in descending order\n",
    "    ranked_indices = np.argsort(sim_scores)[::-1]\n",
    "\n",
    "    # Build a mapping of index -> news_id (since we used .values())\n",
    "    idx_to_aid = list(article_vectors.keys())\n",
    "\n",
    "    # Exclude articles already clicked\n",
    "    recommendations = []\n",
    "    for idx in ranked_indices:\n",
    "        candidate_aid = idx_to_aid[idx]\n",
    "        if candidate_aid not in valid_clicked:\n",
    "            recommendations.append(candidate_aid)\n",
    "        if len(recommendations) == top_k:\n",
    "            break\n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "fake_behaviors = {  # user_id -> list of clicked articles\n",
    "    'U123': ['N55528', 'N61837'],\n",
    "    'U456': ['N38324']\n",
    "}\n",
    "\n",
    "user_id = 'U123'\n",
    "recommended = recommend_for_user(user_id, fake_behaviors[user_id], article_ids, article_vectors, top_k=5)\n",
    "print(f\"Recommendations for user {user_id}:\", recommended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94557ef03d619045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T10:57:49.543300600Z",
     "start_time": "2025-03-11T10:57:46.989153700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique users: 49108\n",
      "User: U13740\n",
      "Clicked articles: ['N55189', 'N42782', 'N34694', 'N45794', 'N18445', 'N63302', 'N10414', 'N19347', 'N31801', 'N55189'] ...\n",
      "Recommendations for user U13740: []\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_all_clicked_articles(behaviors_df):\n",
    "    \"\"\"\n",
    "    Returns a dict: user_id -> list of clicked articles across all impressions.\n",
    "    \"\"\"\n",
    "    user_clicks = defaultdict(list)\n",
    "    \n",
    "    for i, row in behaviors_df.iterrows():\n",
    "        # 'clicked' is the 4th column\n",
    "        clicked_str = row['history']  # e.g. \"N100 N200 N300 ...\"\n",
    "        if not isinstance(clicked_str, str):\n",
    "            continue\n",
    "        clicked_list = clicked_str.split()\n",
    "        \n",
    "        user_id = row['user_id']\n",
    "        user_clicks[user_id].extend(clicked_list)\n",
    "        \n",
    "    return dict(user_clicks)\n",
    "\n",
    "# Build a dictionary of user->clicked articles\n",
    "user_click_map = get_all_clicked_articles(behaviors_train_df)\n",
    "print(f\"Total unique users: {len(user_click_map)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Grab one user ID from the dictionary\n",
    "real_user_id = list(user_click_map.keys())[0]\n",
    "user_clicked_articles = user_click_map[real_user_id]\n",
    "\n",
    "print(f\"User: {real_user_id}\")\n",
    "print(f\"Clicked articles: {user_clicked_articles[:10]} ...\")  # print first 10\n",
    "\n",
    "\n",
    "recommended = recommend_for_user(\n",
    "    real_user_id,              # user_id\n",
    "    user_clicked_articles,     # all articles they clicked\n",
    "    article_ids,               # list of news_ids that have embeddings\n",
    "    article_vectors,           # dict mapping news_id -> 100-dim vector\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(f\"Recommendations for user {real_user_id}:\", recommended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9be22658742f9551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T10:57:49.793605700Z",
     "start_time": "2025-03-11T10:57:49.543660200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No user found who clicked an article with embeddings!\n"
     ]
    }
   ],
   "source": [
    "valid_user_id = None\n",
    "\n",
    "for user_id, clicked_articles in user_click_map.items():\n",
    "    # Check if any clicked article is in article_vectors\n",
    "    valid_clicked = [aid for aid in clicked_articles if aid in article_vectors]\n",
    "    # If there's at least 1 article with an embedding, we can recommend\n",
    "    if len(valid_clicked) > 0:\n",
    "        valid_user_id = user_id\n",
    "        break\n",
    "\n",
    "if valid_user_id is None:\n",
    "    print(\"No user found who clicked an article with embeddings!\")\n",
    "else:\n",
    "    print(f\"Found user: {valid_user_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7256e150eac11b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T11:04:00.345762100Z",
     "start_time": "2025-03-11T11:04:00.322301700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example shared users: ['U54911', 'U8857', 'U83369', 'U21345', 'U8058']\n",
      "Total users in Train: 50000\n",
      "Total users in Validation: 50000\n",
      "Users in both: 5943\n",
      "Users only in Train: 44057\n",
      "Users only in Val: 44057\n",
      "Some train users do not appear in validation.\n",
      "Example user only in train: ['U72339', 'U42080', 'U66792', 'U22515', 'U13112']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Extract unique users from each behaviors DataFrame\n",
    "train_users = set(behaviors_train_df['user_id'].unique())\n",
    "val_users = set(behaviors_dev_df['user_id'].unique())\n",
    "\n",
    "# Find the overlap and differences\n",
    "shared_users = train_users.intersection(val_users)\n",
    "only_in_train = train_users - val_users\n",
    "only_in_val = val_users - train_users\n",
    "\n",
    "shared_list = list(shared_users)\n",
    "print(\"Example shared users:\", shared_list[:5])\n",
    "\n",
    "# Summaries\n",
    "print(f\"Total users in Train: {len(train_users)}\")\n",
    "print(f\"Total users in Validation: {len(val_users)}\")\n",
    "print(f\"Users in both: {len(shared_users)}\")\n",
    "print(f\"Users only in Train: {len(only_in_train)}\")\n",
    "print(f\"Users only in Val: {len(only_in_val)}\")\n",
    "\n",
    "# Check if EVERY train user is in validation\n",
    "if len(only_in_train) == 0:\n",
    "    print(\"All train users also appear in validation.\")\n",
    "else:\n",
    "    print(\"Some train users do not appear in validation.\")\n",
    "    # Optionally print some of them:\n",
    "    print(\"Example user only in train:\", list(only_in_train)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbb2fb42070a6757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T12:53:58.934648400Z",
     "start_time": "2025-03-11T12:53:45.280676900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 50000\n",
      "Dev users: 50000\n",
      "Test users: 702005\n",
      "Users in all three: 4608\n",
      "Users in train and dev only: 5943\n",
      "Users in train and test only: 38458\n",
      "Users in dev and test only: 38576\n",
      "Users only in train: 10207\n",
      "Users only in dev: 10089\n",
      "Users only in test: 629579\n",
      "Some users present in both train and test:\n",
      "['U72339', 'U42080', 'U66792', 'U22515', 'U8857', 'U83369', 'U60368', 'U10184', 'U65723', 'U77858']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Adjust your paths accordingly\n",
    "train_file = '../MINDsmall_train/behaviors.tsv'\n",
    "dev_file   = '../MINDsmall_dev/behaviors.tsv'\n",
    "test_file  = '../MINDlarge_test/behaviors.tsv'\n",
    "\n",
    "# Column names based on the MIND dataset's behaviors file\n",
    "cols = ['impression_id', 'user_id', 'time', 'history', 'impressions']\n",
    "\n",
    "train_df = pd.read_csv(train_file, sep='\\t', header=None, names=cols)\n",
    "dev_df   = pd.read_csv(dev_file,   sep='\\t', header=None, names=cols)\n",
    "test_df  = pd.read_csv(test_file,  sep='\\t', header=None, names=cols)\n",
    "\n",
    "train_users = set(train_df['user_id'].unique())\n",
    "dev_users   = set(dev_df['user_id'].unique())\n",
    "test_users  = set(test_df['user_id'].unique())\n",
    "\n",
    "# Intersection or difference checks\n",
    "all_three = train_users & dev_users & test_users\n",
    "train_dev = train_users & dev_users\n",
    "train_test = train_users & test_users\n",
    "dev_test = dev_users & test_users\n",
    "\n",
    "print(f'Train users: {len(train_users)}')\n",
    "print(f'Dev users: {len(dev_users)}')\n",
    "print(f'Test users: {len(test_users)}')\n",
    "\n",
    "print(f'Users in all three: {len(all_three)}')\n",
    "print(f'Users in train and dev only: {len(train_dev)}')\n",
    "print(f'Users in train and test only: {len(train_test)}')\n",
    "print(f'Users in dev and test only: {len(dev_test)}')\n",
    "\n",
    "print(f'Users only in train: {len(train_users - dev_users - test_users)}')\n",
    "print(f'Users only in dev: {len(dev_users - train_users - test_users)}')\n",
    "print(f'Users only in test: {len(test_users - train_users - dev_users)}')\n",
    "\n",
    "print(\"Some users present in both train and test:\")\n",
    "print(list(train_test)[:10])  # Show the first 10 users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4069e560133ac1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
